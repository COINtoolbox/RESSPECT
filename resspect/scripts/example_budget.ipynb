{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import resspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  3561  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "Loaded  1000  train samples!\n",
      "Loaded  1000  test samples!\n",
      "Loaded  1000  validation samples!\n",
      "\n",
      "\n",
      "** Inside build_orig_samples: **\n",
      "Training set size:  1000\n",
      "Test set size:  1000\n",
      "Validation set size:  1000\n",
      "Pool set size:  3561\n",
      "   From which queryable:  1000 \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  20 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1000\n",
      "   ... test:  1000\n",
      "   ... validation:  1000\n",
      "   ... pool:  3561 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1000, 20)\n",
      "   ... train_labels:  (1000,)\n",
      "   ... pool_features:  (3561, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.862, 0.5294117647058824, 0.8289473684210527, 0.32698961937716264]\n",
      "\n",
      " queried obj index:  [9, 393, 2303, 1568, 2444, 1341, 2657, 2417, 2685, 3135, 3018, 62]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3561 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1012\n",
      "   ... test:  1000\n",
      "   ... validation:  1000\n",
      "   ... pool:  3549 \n",
      "\n",
      "Loaded  3561  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1012\n",
      "Test set size:  3549\n",
      "Validation set size:  3549\n",
      "Pool set size:  3549\n",
      "    From which queryable:  563\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  21 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1012\n",
      "   ... test:  3549\n",
      "   ... validation:  3549\n",
      "   ... pool:  3549 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1012, 20)\n",
      "   ... train_labels:  (1012,)\n",
      "   ... pool_features:  (3549, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7731755424063116, 0.0024906600249066002, 0.3333333333333333, 0.0003558085749866572]\n",
      "\n",
      " queried obj index:  [2174, 931, 675, 3210, 3498, 2498, 2557, 936, 1931, 753, 52, 2293, 656, 1496, 1013, 90, 910]\n",
      "Prob [nIa, Ia]:  [0.52 0.48]\n",
      "size of pool:  3549 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1029\n",
      "   ... test:  3532\n",
      "   ... validation:  3532\n",
      "   ... pool:  3532 \n",
      "\n",
      "Loaded  3561  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1029\n",
      "Test set size:  3532\n",
      "Validation set size:  3532\n",
      "Pool set size:  3532\n",
      "    From which queryable:  546\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  22 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1029\n",
      "   ... test:  3532\n",
      "   ... validation:  3532\n",
      "   ... pool:  3532 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1029, 20)\n",
      "   ... train_labels:  (1029,)\n",
      "   ... pool_features:  (3532, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7743488108720272, 0.020100502512562814, 0.48484848484848486, 0.004800120003000075]\n",
      "\n",
      " queried obj index:  [1122, 2817, 1197, 735, 161, 1916, 2055, 2418, 1904, 2944, 3375, 3195, 1871, 2163, 2074]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3532 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1044\n",
      "   ... test:  3517\n",
      "   ... validation:  3517\n",
      "   ... pool:  3517 \n",
      "\n",
      "Loaded  3561  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3561\n",
      "Validation set size:  3561\n",
      "Pool set size:  3561\n",
      "   From which queryable:  575 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1044\n",
      "Test set size:  3517\n",
      "Validation set size:  3517\n",
      "Pool set size:  3517\n",
      "    From which queryable:  531\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  23 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1044\n",
      "   ... test:  3517\n",
      "   ... validation:  3517\n",
      "   ... pool:  3517 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1044, 20)\n",
      "   ... train_labels:  (1044,)\n",
      "   ... pool_features:  (3517, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7767984077338641, 0.07614213197969544, 0.5128205128205128, 0.019777177137583226]\n",
      "\n",
      " queried obj index:  [2706, 2052, 3295, 1403, 2412, 862, 458, 3085, 671, 1766, 1644, 1645, 1908, 882, 3123]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3517 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1059\n",
      "   ... test:  3502\n",
      "   ... validation:  3502\n",
      "   ... pool:  3502 \n",
      "\n",
      "Loaded  3743  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1059\n",
      "Test set size:  3684\n",
      "Validation set size:  3684\n",
      "Pool set size:  3684\n",
      "    From which queryable:  534\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  24 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1059\n",
      "   ... test:  3684\n",
      "   ... validation:  3684\n",
      "   ... pool:  3684 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1059, 20)\n",
      "   ... train_labels:  (1059,)\n",
      "   ... pool_features:  (3684, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7749728555917481, 0.06545454545454546, 0.48214285714285715, 0.015502392344497606]\n",
      "\n",
      " queried obj index:  [2289, 462, 1457, 3484, 3197, 178, 3663, 2986, 1184, 353, 2501, 1531, 1395, 1402, 1224]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3684 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1074\n",
      "   ... test:  3669\n",
      "   ... validation:  3669\n",
      "   ... pool:  3669 \n",
      "\n",
      "Loaded  3743  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1074\n",
      "Test set size:  3669\n",
      "Validation set size:  3669\n",
      "Pool set size:  3669\n",
      "    From which queryable:  519\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  25 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1074\n",
      "   ... test:  3669\n",
      "   ... validation:  3669\n",
      "   ... pool:  3669 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1074, 20)\n",
      "   ... train_labels:  (1074,)\n",
      "   ... pool_features:  (3669, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7735077677841373, 0.0488997555012225, 0.43010752688172044, 0.009829096583160302]\n",
      "\n",
      " queried obj index:  [1476, 2645, 1746, 380, 2001, 1098, 924, 1357, 1455, 1319, 2978, 736, 948]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3669 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1087\n",
      "   ... test:  3656\n",
      "   ... validation:  3656\n",
      "   ... pool:  3656 \n",
      "\n",
      "Loaded  3743  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1087\n",
      "Test set size:  3656\n",
      "Validation set size:  3656\n",
      "Pool set size:  3656\n",
      "    From which queryable:  506\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  26 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1087\n",
      "   ... test:  3656\n",
      "   ... validation:  3656\n",
      "   ... pool:  3656 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1087, 20)\n",
      "   ... train_labels:  (1087,)\n",
      "   ... pool_features:  (3656, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7718818380743983, 0.09293680297397769, 0.423728813559322, 0.01829464625472002]\n",
      "\n",
      " queried obj index:  [580, 2653, 3137, 3468, 990, 3431, 4, 2027, 2443, 1840, 3630, 3112, 1097]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3656 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1100\n",
      "   ... test:  3643\n",
      "   ... validation:  3643\n",
      "   ... pool:  3643 \n",
      "\n",
      "Loaded  3743  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  587 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1100\n",
      "Test set size:  3643\n",
      "Validation set size:  3643\n",
      "Pool set size:  3643\n",
      "    From which queryable:  493\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  27 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1100\n",
      "   ... test:  3643\n",
      "   ... validation:  3643\n",
      "   ... pool:  3643 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1100, 20)\n",
      "   ... train_labels:  (1100,)\n",
      "   ... pool_features:  (3643, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7718912983804557, 0.07740324594257178, 0.4025974025974026, 0.014198228545678848]\n",
      "\n",
      " queried obj index:  [87, 1793, 1863, 3189, 1687, 2260, 2576, 164, 3096, 1550, 2764, 286, 1765]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3643 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1113\n",
      "   ... test:  3630\n",
      "   ... validation:  3630\n",
      "   ... pool:  3630 \n",
      "\n",
      "Loaded  3743  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  625 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3743\n",
      "Validation set size:  3743\n",
      "Pool set size:  3743\n",
      "   From which queryable:  625 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1113\n",
      "Test set size:  3630\n",
      "Validation set size:  3630\n",
      "Pool set size:  3630\n",
      "    From which queryable:  524\n",
      "**************************** \n",
      "\n",
      "\n",
      " ****************************\n",
      " Processing night:  28 \n",
      "\n",
      "\n",
      " Before update_samples:\n",
      "   ... train:  1113\n",
      "   ... test:  3630\n",
      "   ... validation:  3630\n",
      "   ... pool:  3630 \n",
      "\n",
      "\n",
      " Inside classify_bootstrap: \n",
      "   ... train_features:  (1113, 20)\n",
      "   ... train_labels:  (1113,)\n",
      "   ... pool_features:  (3630, 20)\n",
      "\n",
      " Metrics names:  ['accuracy', 'efficiency', 'purity', 'fom']\n",
      "Metrics values:  [0.7636363636363637, 0.07547169811320754, 0.32786885245901637, 0.010555482253595462]\n",
      "\n",
      " queried obj index:  [352, 2912, 891, 1188, 3442, 1368, 1601, 2272, 1939, 3414, 2480, 173, 2160, 2]\n",
      "Prob [nIa, Ia]:  [0.5 0.5]\n",
      "size of pool:  3630 \n",
      "\n",
      "\n",
      " After update_samples:\n",
      "   ... train:  1127\n",
      "   ... test:  3616\n",
      "   ... validation:  3616\n",
      "   ... pool:  3616 \n",
      "\n",
      "Loaded  3751  samples!\n",
      "\n",
      "\n",
      "** Inside build_random_training: **\n",
      "Training set size:  0\n",
      "Test set size:  3751\n",
      "Validation set size:  3751\n",
      "Pool set size:  3751\n",
      "   From which queryable:  625 \n",
      "\n",
      "\n",
      "\n",
      "** Inside build_samples ** : \n",
      "Training set size:  0\n",
      "Test set size:  3751\n",
      "Validation set size:  3751\n",
      "Pool set size:  3751\n",
      "   From which queryable:  625 \n",
      "\n",
      "\n",
      " After reading tomorrow data:\n",
      "Training set size:  1127\n",
      "Test set size:  3624\n",
      "Validation set size:  3624\n",
      "Pool set size:  3624\n",
      "    From which queryable:  510\n",
      "**************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot = True\n",
    "loop = True\n",
    "data_path = '/home/noble/data/resspect/IAL2020/'\n",
    "strategies_list = ['RandomSampling', 'UncSampling', 'UncSamplingEntropy', 'UncSamplingLeastConfident',\n",
    "                          'UncSamplingMargin', 'QBDMI', 'QBDEntropy']\n",
    "\n",
    "if loop:\n",
    "    from resspect import time_domain_loop\n",
    "    \n",
    "    # set parameters\n",
    "    days = [20, 30]# 181]\n",
    "    training = 'original'\n",
    "    v = '2'\n",
    "    strategy = strategies_list[4]\n",
    "    n_estimators = 10\n",
    "    batch = None # use budgets instead\n",
    "    budgets = (6. * 3600, 6. * 3600)\n",
    "    classifier = 'RandomForest'\n",
    "    clf_bootstrap = True\n",
    "    feature_method = 'Bazin'\n",
    "    screen = True\n",
    "    fname_pattern = ['day_', '.dat']\n",
    "    canonical = False\n",
    "    queryable= True\n",
    "    \n",
    "    case = 'representative'\n",
    "    sep_files = True\n",
    "    \n",
    "    output_diag_file = 'results/' + case + '/metrics_' + strategy + '_' + str(training) + \\\n",
    "                       '_' + case + '_v' + str(v) + '.dat'\n",
    "    output_query_file = 'results/' + case + '/queried_' + strategy + '_' + str(training) + \\\n",
    "                        '_' + case + '_v' + str(v) + '.dat'\n",
    "    path_to_features_dir = data_path + case + '/pool/'\n",
    "  \n",
    "    \n",
    "    path_to_ini_files = {}\n",
    "    path_to_ini_files['train'] = data_path + case + '/Train.csv'\n",
    "    path_to_ini_files['test'] = data_path + case + '/Test.csv'\n",
    "    path_to_ini_files['validation'] = data_path + case + '/Validation.csv'\n",
    "    survey='DES'\n",
    "    \n",
    "    # run time domain loop\n",
    "    time_domain_loop(days=days, output_metrics_file=output_diag_file,\n",
    "                     output_queried_file=output_query_file,\n",
    "                     path_to_features_dir=path_to_features_dir,\n",
    "                     strategy=strategy, fname_pattern=fname_pattern,\n",
    "                     batch=batch, classifier=classifier, \n",
    "                     clf_bootstrap=clf_bootstrap, budgets=budgets,\n",
    "                     canonical=canonical, sep_files=sep_files,\n",
    "                     screen=screen, initial_training=training, path_to_ini_files=path_to_ini_files,\n",
    "                     survey=survey, queryable=queryable, n_estimators=n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 19 fields in line 4, saw 21\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-096d3d4f08f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         cv.load_metrics(path_to_files=path_to_files,\n\u001b[0;32m---> 29\u001b[0;31m                         strategies_list=strategies_list)\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_plot_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         cv.plot_metrics(output_plot_file=output_plot,\n",
      "\u001b[0;32m~/Documents/code/RESSPECT/resspect/plot_results.py\u001b[0m in \u001b[0;36mload_metrics\u001b[0;34m(self, path_to_files, strategies_list, metrics_name)\u001b[0m\n\u001b[1;32m    201\u001b[0m             self.strategies[name] = pd.read_csv(path_to_files[i],\n\u001b[1;32m    202\u001b[0m                                                 \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                                                 index_col=False)\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# get metrics names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/resspect/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/resspect/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/resspect/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/resspect/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 19 fields in line 4, saw 21\n"
     ]
    }
   ],
   "source": [
    "if plot:\n",
    "    from resspect.plot_results import Canvas\n",
    "    \n",
    "    train = 'original'\n",
    "    case = 'representative'\n",
    "    \n",
    "    for v in range(2, 3):\n",
    "    \n",
    "        # define parameters  \n",
    "        path_to_files = ['results/' + case + '/metrics_RandomSampling_' + str(train) + \\\n",
    "                         '_' + case + '_v' + str(v).zfill(1) +'.dat',\n",
    "                         'results/' + case + '/metrics_UncSampling_' + str(train) + \\\n",
    "                         '_' + case + '_v' + str(v).zfill(1) +'.dat',\n",
    "                        'results/' + case + '/metrics_UncSamplingEntropy_' + str(train) + \\\n",
    "                         '_' + case + '_v' + str(v).zfill(1) +'.dat',\n",
    "                        'results/' + case + '/metrics_UncSamplingLeastConfident_' + str(train) + \\\n",
    "                         '_' + case + '_v' + str(v).zfill(1) +'.dat',\n",
    "                        'results/' + case + '/metrics_UncSamplingMargin_' + str(train) + \\\n",
    "                         '_' + case + '_v' + str(v).zfill(1) +'.dat']\n",
    "        strategies_list = ['RandomSampling', 'UncSampling', 'UncSamplingEntropy', 'UncSamplingLeastConfident',\n",
    "                          'UncSamplingMargin', 'QBDMI', 'QBDEntropy']\n",
    "        #strategies_list = [ 'UncSampling']\n",
    "        output_plot = 'plots/' + case + '/metrics_' + str(train) + '_' + case + '_v' + str(v).zfill(1) +'.png'\n",
    "  \n",
    "        #Initiate the Canvas object, read and plot the results for\n",
    "        # each metric and strategy.\n",
    "        cv = Canvas()\n",
    "        cv.load_metrics(path_to_files=path_to_files,\n",
    "                        strategies_list=strategies_list)\n",
    "        cv.set_plot_dimensions()\n",
    "        cv.plot_metrics(output_plot_file=output_plot,\n",
    "                        strategies_list=strategies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
